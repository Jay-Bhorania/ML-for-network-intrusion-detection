{"cells":[{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\nfrom numpy import array\n\n#read training data\ninitial_train_data = sc.textFile(\"dbfs:/FileStore/tables/segpevp71489465231873/train_data.csv\")\nheader = initial_train_data.first()\n\ndef parse_data(data):\n  data_split = line.split(\",\")\n  return LabeledPoint(data_split[1], data_split[2:])\n\ntrain_data = initial_train_data.filter(lambda d: d != header).map(\n  lambda d: LabeledPoint(d.split(',')[1], d.split(',')[2:])\n).cache()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#read test data\ninitial_test_data = sc.textFile(\"dbfs:/FileStore/tables/2e7b7q841489465266479/test_data.csv\")\ntest_data = initial_test_data.filter(lambda d: d != header).map(\n  lambda d: LabeledPoint(d.split(',')[1], d.split(',')[2:])\n).cache()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Perform logistic regression\nfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS\n\nlrm_output = []\n\nfor _ in range(10):\n\n  lrm = LogisticRegressionWithLBFGS.train(train_data)\n  \n  predictionsAndLabels = test_data.map(\n    lambda p: (p.label, lrm.predict(p.features))\n  )\n\n  true_pos = float(predictionsAndLabels.filter(lambda (v, p): v == 1 and p == 1).count())\n  true_neg = float(predictionsAndLabels.filter(lambda (v, p): v == 0 and p == 0).count())\n  false_pos = float(predictionsAndLabels.filter(lambda (v, p): v == 0 and p == 1).count())\n  false_neg = float(predictionsAndLabels.filter(lambda (v, p): v == 1 and p == 0).count())\n  \n\n  accuracy = (true_pos + true_neg) / (true_pos + false_neg + false_pos + true_neg)\n  recall = false_pos / (false_pos + true_neg)\n  precision = true_pos / (true_pos + false_pos)\n  f1_score = 2 * ((recall * precision) / (recall + precision))\n  \n  lrm_output.append((round(accuracy,5), round(recall,5), round(precision,5), round(f1_score,5)))\n  \nprint display(lrm_output)\n  "],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Perform random forest classifier\nfrom pyspark.mllib.tree import RandomForest\n\nrfc_output = []\n\nfor _ in range(10):\n  rfc = RandomForest.trainClassifier(\n    train_data, 2, categoricalFeaturesInfo={40:2, 41:2, 42:2, 43:2, 44:2, 45:2, 46:2, 47:2, 48:2, 49:2}\n    , numTrees=100, featureSubsetStrategy=\"auto\", impurity='gini', maxDepth=3, maxBins=200\n  )\n  \n  predictions = rfc.predict(test_data.map(\n      lambda d: d.features\n    ))\n  labelsAndPredictions = test_data.map(\n    lambda lp: lp.label\n  ).zip(predictions)\n  \n  true_pos = float(predictionsAndLabels.filter(lambda (v, p): v == 1 and p == 1).count())\n  true_neg = float(predictionsAndLabels.filter(lambda (v, p): v == 0 and p == 0).count())\n  false_pos = float(predictionsAndLabels.filter(lambda (v, p): v == 0 and p == 1).count())\n  false_neg = float(predictionsAndLabels.filter(lambda (v, p): v == 1 and p == 0).count())\n  \n\n  accuracy = (true_pos + true_neg) / (true_pos + false_neg + false_pos + true_neg)\n  recall = false_pos / (false_pos + true_neg)\n  precision = true_pos / (true_pos + false_pos)\n  f1_score = 2 * ((recall * precision) / (recall + precision))\n  \n  rfc_output.append((round(accuracy,5), round(recall,5), round(precision,5), round(f1_score,5)))\n  \nprint display(rfc_output)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Gradient boosted classifier\nfrom pyspark.mllib.tree import GradientBoostedTrees\n\ngbt_output = []\n\nfor _ in range(10):\n  gbt = GradientBoostedTrees.trainClassifier(\n    train_data, categoricalFeaturesInfo={40:2, 41:2, 42:2, 43:2, 44:2, 45:2, 46:2, 47:2, 48:2, 49:2}\n    , numIterations=5\n  )\n  \n  predictions = gbt.predict(test_data.map(lambda d: d.features))\n  labelsAndPredictions = test_data.map(\n    lambda lp: lp.label\n  ).zip(predictions)\n  \n  true_pos = float(predictionsAndLabels.filter(lambda (v, p): v == 1 and p == 1).count())\n  true_neg = float(predictionsAndLabels.filter(lambda (v, p): v == 0 and p == 0).count())\n  false_pos = float(predictionsAndLabels.filter(lambda (v, p): v == 0 and p == 1).count())\n  false_neg = float(predictionsAndLabels.filter(lambda (v, p): v == 1 and p == 0).count())\n  \n\n  accuracy = (true_pos + true_neg) / (true_pos + false_neg + false_pos + true_neg)\n  recall = false_pos / (false_pos + true_neg)\n  precision = true_pos / (true_pos + false_pos)\n  f1_score = 2 * ((recall * precision) / (recall + precision))\n  \n  gbt_output.append((round(accuracy,5), round(recall,5), round(precision,5), round(f1_score,5)))\n  \nprint display(gbt_output)"],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"HW1","notebookId":330450496229965},"nbformat":4,"nbformat_minor":0}
